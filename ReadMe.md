Experiment 1: Image / Video Reading and Display
This experiment introduces basic image and video acquisition using OpenCV. It demonstrates how to read images in different modes (grayscale, colour, unchanged), capture live video from a camera, display frames in real time, and store the video stream. It helps students understand image I/O operations and real-time video handling in computer vision.

Experiment 2: Image Transformations
This experiment focuses on geometric transformations such as scaling, translation, and rotation. Using OpenCV, the original image is transformed mathematically and displayed alongside the output. The experiment helps in understanding how coordinate transformations affect image geometry and are used in image alignment and preprocessing.

Experiment 3: Histogram Analysis
In this experiment, a program is developed to compute and plot the histogram of a grayscale image. It also performs histogram equalization to improve image contrast. This experiment explains how pixel intensity distribution affects image appearance and how histogram equalization enhances visibility in low-contrast images.

Experiment 4: Edge Detection
This experiment implements Canny Edge Detection, a widely used multi-stage edge detection algorithm. It includes noise reduction, gradient calculation, non-maximum suppression, and hysteresis thresholding. The experiment highlights how edges represent object boundaries and structural information in images.

Experiment 5: Image Enhancement
This experiment applies spatial domain filtering techniques to enhance image quality. Smoothing filters reduce noise, while sharpening filters enhance edges and fine details. The experiment demonstrates how filtering improves visual quality and prepares images for further analysis.

Experiment 6: Convolution, Filtering, and Motion Blur in Digital Images
This experiment explores convolution-based filtering and simulates motion blur. It shows how kernels are applied to images and how motion affects image clarity. The experiment helps in understanding real-world degradation effects and restoration challenges in digital images.


Experiment 7: Corner Detection
This experiment implements corner detection algorithms such as Harris Corner Detector or SIFT. Corners are important feature points used in object recognition and image matching. The experiment explains how intensity variations in multiple directions indicate corner points.

Experiment 8: Texture Segmentation using Gabor Filters
In this experiment, a bank of Gabor filters is used for texture segmentation. Gabor filters analyse images in both spatial and frequency domains. This experiment demonstrates how texture patterns can be identified and segmented based on orientation and frequency characteristics.

Experiment 9: Image Segmentation
This experiment designs an image segmentation framework using classical methods (thresholding, region-based segmentation) and learning-based approaches. The performance of different techniques is compared on natural images, highlighting strengths and limitations of traditional and modern segmentation methods.

Experiment 10: Object Detection
This experiment implements and compares traditional object detection techniques with deep learning-based methods. It demonstrates how modern approaches improve detection accuracy and robustness. The experiment provides insight into the evolution of object detection in computer vision.
